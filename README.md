Parallel Programming Scrapbook
Welcome to my Parallel Programming Projects repository! This repository showcases the various projects I completed during my parallel programming class. Throughout the course, I delved into different aspects of parallel computing, ranging from hardware and software fundamentals to specific programming models and techniques. Below is an overview of what you'll find in this repository.

Overview
This repository contains a comprehensive collection of projects that demonstrate my understanding and application of parallel programming concepts. Each project highlights a different area of parallel computing:

Parallel Hardware and Software
In this section, I explored the essential components and architecture of parallel systems, including multi-core processors, memory hierarchies, and interconnects. I also examined the software tools and environments used for parallel programming.

Distributed Memory Programming with MPI
Message Passing Interface (MPI) is a powerful standard for programming parallel applications across distributed memory systems. Here, I implemented various projects using MPI to demonstrate techniques such as parallel matrix multiplication, data distribution, and inter-process communication.

Shared Memory Programming with Pthreads
POSIX Threads (Pthreads) provide a standard way to write parallel programs for shared memory systems. This section contains projects where I utilized Pthreads to create concurrent applications, including parallel sorting algorithms and the management of concurrent data structures.

Shared Memory Programming with OpenMP
OpenMP is a widely-used API that simplifies parallel programming for shared memory architectures. In these projects, I employed OpenMP directives to parallelize loops, manage tasks, and optimize performance for multi-threaded applications.

GPU Programming with CUDA
CUDA, developed by NVIDIA, is a parallel computing platform and programming model that leverages the power of GPUs. In this section, I explored GPU programming with CUDA, working on projects such as parallel reduction algorithms and image processing tasks to harness the computational capabilities of GPUs.
